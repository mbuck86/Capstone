```{r echo=FALSE}
# Importing packages for functionality throughout the document
library(tidyverse)
library(ggplot2)
library(QuantPsyc)
library(ISLR)
library(boot)
library(jtools)
library(ggrepel)
library(factoextra)
```

Introduction:
What is the value of education after high school? Is going to university actually worth the great cost or debt that going to university
can incur? Is getting into a more selective school which takes only students with great test scores and perfect GPAs worth the stress
of studying to obtain those results? These are questions that many high school educators must consider when their students come to them
asking for advice regarding their future. With the current trend in education being to push students towards university regardless of
their individual needs or desires, these are questions that require answers. The answers to these questions when responding to them in
the real world are complex and the answer one gives can vary student by student, but what if these are questions we can answer
mathematically? What if it is possible to analyze data regarding university entry statistics and statistics from students who have left
university to see what metrics predict student success later in life? Generating a product that can tell a high school student who is
interested in pursuing a bachelor’s degree exactly what traits to look for in a school that is going to lead them to success, or tell
them what test scores they need to achieve to maximize their chances of success in the future could be invaluable in assisting the
countless students who finish high school every year not knowing where their future is going to take them.

```{r echo=FALSE}
#Importing Data
FF <- read.csv("CollegeScorecard_Raw_Data/MERGED2014_15_PP.csv", stringsAsFactors = FALSE)
Uni <- subset(FF, PREDDEG == 3)

# Selecting some columns to remove to try to make the data frame more
# manageable and less noisy.
removeCols1<- c(1:3, 5, 7:12) 
Uni <- Uni[-removeCols1]

removeCols2<- c(4, 10:23)
Uni <- Uni[-removeCols2]

# Removing specific program related variables
Uni <- Uni %>% dplyr::select(-starts_with("PCIP"), -starts_with("CIP"))

# Removing more Misc variables, mostly demographics enrollment stats
Uni <- Uni %>% dplyr::select(-DISTANCEONLY, -starts_with("UGDS_"),
                      -starts_with("UG_"), -starts_with('PPTUG_'),-CURROPER)

# Removing demographics based cost information
Uni <- Uni %>% dplyr::select(-starts_with('NPT41'), -starts_with('NPT42'), -starts_with('NPT43'), -starts_with('NPT44'),
                      -starts_with('NPT45'), -starts_with('NPT4_0'), -starts_with('NPT4_3'),-starts_with('NPT4_7'))

# Removing more demographics based enrollment information, and more misc
Uni <- Uni %>% dplyr::select(-starts_with("NUM4"), -starts_with("TUITIONFEE"), -TUITFTE, -INEXPFTE, -PFTFAC, -PCTPELL,
                      -starts_with("D150_"), -starts_with("C150_4_"), -PFTFTUG1_EF, - starts_with("C150_L4_"))

# More misc variables
Uni <- Uni %>% dplyr::select(-starts_with("C200_"), -starts_with("D200_"), - starts_with("RET_"), -POOLYRS200, -PCTFLOAN, -UG25ABV, 
                              -CDR2, -CDR3, -starts_with("DEATH_"), -starts_with("COMP_"), -starts_with("WDRAW_"), -starts_with("ENRL_"),
                              -starts_with("UNKN_"), -starts_with("LO_INC_"), -starts_with("MD_INC_"), -starts_with("HI_INC_"),
                      -starts_with("DEP_"),
                              -starts_with("IND_"), -starts_with("FEMALE_"), -starts_with("MALE_"), -starts_with("PELL_"), -starts_with("NOPELL_"))

#More misc variables: financial
Uni <- Uni %>% dplyr::select(-starts_with("LOAN_"), -starts_with("NOLOAN_"), -starts_with("FIRSTGEN_"), -starts_with("NOT1STGEN_"))

#removing repayment variables:
Uni <- Uni %>% dplyr::select(-starts_with("RPY_"), -starts_with("COMPL_"), -starts_with("NONCOM_"), -starts_with("NOTFIRSTGEN_"))

#removing more financial variables
Uni <- Uni %>% dplyr::select(-"INC_PCT_LO", -'PAR_ED_PCT_1STGEN', -'INC_PCT_M1', -'INC_PCT_M2', -'INC_PCT_H1', -'INC_PCT_H1', -'INC_PCT_H2',
                              -starts_with("APPL_SCH_PCT"), -starts_with("PAR_ED_PCT"), -starts_with("OVERALL_"))

#removing more misc
Uni <- Uni %>% dplyr::select(-starts_with("OMA"), -starts_with("OME"))

#more: Values I kept tha tmight be interesting, but have no useful info/all NA
Uni <- Uni %>% dplyr::select(-"POOLYRS", -"MENONLY", -"WOMENONLY", -"RELAFFIL")

#getting rid of numbers of students in debt categories.
Uni <- Uni %>% dplyr::select(-DEBT_N, -GRAD_DEBT_N, -CUML_DEBT_N,-CUML_DEBT_P90,-CUML_DEBT_P75,-CUML_DEBT_P25,-CUML_DEBT_P10,
                              -INC_N, -PAR_ED_N, -APPL_SCH_N)

#getting rid of numbers of students and fafsa data
Uni <- Uni %>% dplyr::select(-starts_with("COUNT_WNE_"), -starts_with("FSEND_"))
```

The Data:
The data being used in this analysis is data maintained by the US government and used the the creation of the website College Scorecard.
Thedata contains information regarding almost every active post-secondary school  in the United States, including trade-schools, community
colleges, universities, and graduate schools. This analysis is going to focus on schools that primarily award bachelor’s degrees because
that is the primary direction secondary school students are pushed in after they finish high school. This dataset contains close to two
thousand variables, which fall into various categories, such as:
* Test score statistics of students accepted at the  universities including 25th percentile scores, median scores, and 75 percentile scores. There are also section statistics for the SAT and ACT respectively. There is also an average SAT equivalent variable which aggregates and averages scores from each test.
* Variables which describe the availability and enrollment rates of various fields of study at each of the universities.
* Various demographic variables that account for things like race, financial status, and first generation college students.
* Employment rates and median salary statistics of students at various time periods after they have entered school(for example, six years or ten years after).
* Various variables to describe the school rather than the students such as average faculty salary and admission rate.
There are a myriad of questions that this dataset can analyse and it was difficult to decide which variables to keep and which to remove
for this project. There are two large problems with this dataset that make it tricky to work with beyond the large number of variables.
The first problem is that the data is split into academic years as .csv files, which means looking at data across years requires some
amount of tedious work in order to make it so that you can look at everything at the same time. The second is that an exceedingly large
number of observations are incomplete. Many rows are missing critical values, which makes analysis difficult when one is trying to look at
all numbers for all schools.

Data Wrangling:
In order to avoid the complications of a time series analysis, it was decided to focus the project on the most recent academic year that a
reasonable amount of full data was available for. The most recent year that had available student earnings data as well as comprehensive
test data was the 2014-15 academic school year, so that was the dataset that was used.The focus of this analysis is students trying to
earn bachelor’s degrees after high school, and this dataset has a categorical variable that identifies schools based on the primary degree
they award, so this analysis will focus on schools that primarily award bachelor’s degrees based on this identification in the dataset. In
order to clean this dataset most of the work involved checking the documentation of the dataset and determining whether or not various 
sets of variables might be useful in a model predicting future success of students. A large majority of the variables had similar prefixes
and could be removed with a few lines of code. While determining what variables were definitely not going to be used in analysis, the
number of variables went from 1899 to less than 200. The final cleaning step was to convert the numerical statistics to numeric values,
and only select complete observations of the statistics the analysis was going to be using. 

```{r echo=FALSE}
#converting significant mathematical variables to numeric
Uni$ADM_RATE <- as.numeric(Uni$ADM_RATE)
Uni$SATVR25 <- as.numeric(Uni$SATVR25)
Uni$SATVR75 <- as.numeric(Uni$SATVR75)
Uni$SATVRMID <- as.numeric(Uni$SATVRMID)
Uni$SATMT25 <- as.numeric(Uni$SATMT25)
Uni$SATMT75 <- as.numeric(Uni$SATMT75)
Uni$SATMTMID <- as.numeric(Uni$SATMTMID)
Uni$SATWR25 <- as.numeric(Uni$SATWR25)
Uni$SATWR75 <- as.numeric(Uni$SATWR75)
Uni$SATWRMID <- as.numeric(Uni$SATWRMID)
Uni$ACTCMMID <- as.numeric(Uni$ACTCMMID)
Uni$ACTCM25 <- as.numeric(Uni$ACTCM25)
Uni$ACTCM75 <- as.numeric(Uni$ACTCM75)
Uni$ACTEN25 <- as.numeric(Uni$ACTEN25)
Uni$ACTEN75 <- as.numeric(Uni$ACTEN75)
Uni$ACTENMID <- as.numeric(Uni$ACTENMID)
Uni$ACTMTMID <- as.numeric(Uni$ACTMTMID)
Uni$ACTMT75 <- as.numeric(Uni$ACTMT75)
Uni$ACTMT25 <- as.numeric(Uni$ACTMT25)
Uni$ACTWR25 <- as.numeric(Uni$ACTWR25)
Uni$ACTWR75 <- as.numeric(Uni$ACTWR75)
Uni$ACTWRMID <- as.numeric(Uni$ACTWRMID)
Uni$UGDS <- as.numeric(Uni$UGDS)
Uni$COSTT4_A <- as.numeric(Uni$COSTT4_A)
Uni$AVGFACSAL <- as.numeric(Uni$AVGFACSAL)
Uni$C150_4 <- as.numeric(Uni$C150_4)
Uni$MD_EARN_WNE_P10 <- as.numeric(Uni$MD_EARN_WNE_P10)
Uni$C100_4 <- as.numeric(Uni$C100_4)
Uni$SAT_AVG <- as.numeric(Uni$SAT_AVG)
```

Exploratory Data Analysis:
While formulating ideas for how to go about this analysis, the first question that I found pertinent to ask was about graduation rates at 
universities. The U.S. government regularly releases data that shows that poeople who have completed higher levels of education generally
have higher median salaries. Here is a histogram of the four year graduation rates of universities in the dataset:
```{r}
ggplot(Uni, aes(x=C100_4)) + geom_histogram(color='black', fill='blue', bins=50) + 
  labs(title="Four Year Graduation Rates of Universities in the U.S, 2014-2015")

mean(Uni$C100_4, na.rm=TRUE)
median(Uni$C100_4, na.rm=TRUE)
  
```
The mean of the four year graduation rates from schools in this dataset was around 34.21% while the median was 31.03%. While seeing these
statistics I was somewhat shocked. I was surprised to see that only 30% of students typically made it through university in four years,
as it is typically understood that university takes four years to complete. This data has a strange trait of having several 0% graduation rate universities that probably greatly skew that number. Another statistic in this dataset is the six year graduation 
rate:
```{r}
ggplot(Uni, aes(x=C150_4)) + geom_histogram(color='black', fill='blue', bins=50) + 
  labs(title="Six Year Graduation Rates of Universities in the U.S, 2014-2015")

mean(Uni$C150_4, na.rm=TRUE)
median(Uni$C150_4, na.rm=TRUE)
```
The six year graduation rate shows a greatly imrpoved graduation rate over the four year graduation rate, with a mean of around 50.15%
and a median around 49.74%. This still does not seem like a great aspect of the university education system. Most high school students are
sold on the fact that university takes four years to complete, but it seems saying it will takes six years is a far more accurate
reperesentation of reality. While graduation may be a sign of success at university, our dataset contains a variable that is the median
earning of students from that university ten years after entering school. This variable seems to be a better answer to a question regarding
student financial success after attending university, so we will now look at some plots of student earnings vs. some other potential
predictor variables.

```{r}
ggplot(data=Uni, aes(x=SAT_AVG, y=MD_EARN_WNE_P10)) + geom_point() + xlab("Average SAT Equivalent") + ylab('Median Earnings Ten Years After Entering School')
```

This graph is a scatterplot of yearly salaries of students at universities ten years after they had entered university versus the average
SAT equivalent score of students attending those universities. This graph does seem to show some sort of positive relationship, which could
be a surprise if one does not view standardised tests as proper measures of student ability. One thought that may be interesting to consider
is whether or not different standardized tests are better predictors of future financial success.
The following is a graph of the same salary statistic as the previous graph versus cumulative ACT scores. In North Carolina, the ACT is a
test given to every junior in public school for free. Student’s test scores on the ACT are partially included in school report card grades.
This graph also shows a positive relationship between test scores and salaries, to the point that the graphs seem practically identical to
each other. This leads me to believe that it is possible these statistics as well as other test related statistics could be used to predict
future student success.
```{r}
ggplot(data=Uni, aes(x=ACTCMMID, y=MD_EARN_WNE_P10)) + geom_jitter() + xlab("Median Cumulative ACT Score") + ylab('Median Earnings Ten Years After Entering School')
```
It may also be interesting to observe if some other characteristics of these universities also affect success of students in the future. The
other characteristics that will be considered here are: six-year graduation rate, admission rate, and faculty salary. It may appear to be
obvious that graduation rate would affect future salaries of students but it might be useful to check the intuition with this dataset.
```{r}
ggplot(data=Uni, aes(x=C150_4, y=MD_EARN_WNE_P10)) + geom_jitter() + xlab("Six-year Graduation Rate") + ylab('Median Earnings Ten Years After Entering School')
```
This scatter plot is interesting to look at. Having the knowledge that more educated people generally have highe wages, the somewhat
flat curve of this graph seems a bit anomolous. There doesn't seem to be a clear positive relationship until around the 50% graduation
rate mark. This could be attributed to the fact that schools with lower completion rates tend to have lower median salaries since many of 
their past students did not obtain their degrees they were seeking, and therefore their former students recieve lower pay on average because
of the lower completed education level. One additional statistic I was interested in looking to explore when trying to build the model was
average faculty salary. As an educator myself I thought it may be interesting to see if the amount shcool faculty were paid was related to
student success. 
```{r}
ggplot(data=Uni, aes(x=AVGFACSAL, y=MD_EARN_WNE_P10)) + geom_jitter() + xlab("Average Faculty Salary") + ylab('Median Earnings Ten Years After Entering School')
```
The positive correlation between average faculty salary and student earnings shown in this graph was a bit surprising to me. I originally
believed if there was any correlation between the two it would only be slightly correlated, however this graph seems to show a high positive
correlation between faculty salary and student financial success in the future.

Machine Learning:
After performing exploratory analysis I felt comfortable with attempting to build a multiple linear regression model to predict student 
salaries ten years after entering school. Most of the predictors that were chosen seemed to have a close to linear relationship  Through 
the exploratoty data analysis and based off of the questions asked previously in the report, these were the predictors chosen to construct
the initial model of the linear regression:
*Average SAT Equivalent
*Six year graduation rate
*25 percentile, 75th percentile, and median SAT verbal and math sores.
*ACT cumulative, math, and english median scores
*University admission rates
*Average Faculty Salary 
```{r}
#Selecting complete cases based on variables in the model
Uni <- Uni %>% dplyr::select(SAT_AVG, C150_4, C100_4, SATVR25, SATVR75, SATMT25, SATMT75,
                      SATWR25, SATWR75,SATVRMID, SATMTMID, ACTCMMID, ACTENMID, ACTMTMID,
                      ADM_RATE, ADM_RATE_ALL, AVGFACSAL, MD_EARN_WNE_P10, MD_EARN_WNE_P6)

Uni <- na.omit(Uni)

# Creating Linear Models 
Earn <- lm(MD_EARN_WNE_P10~SAT_AVG+C150_4+SATVR25+SATVR75+SATMT25+SATMT75+SATVRMID+SATMTMID+ACTCMMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.1 <- lm(MD_EARN_WNE_P10~SAT_AVG+C150_4+SATVR25+SATVR75+SATMT75+SATVRMID+SATMTMID+ACTCMMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.2 <- lm(MD_EARN_WNE_P10~C150_4+SATVR25+SATVR75+SATMT75+SATVRMID+SATMTMID+ACTCMMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.3 <- lm(MD_EARN_WNE_P10~C150_4+SATVR25+SATVR75+SATMT75+SATVRMID+SATMTMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.4 <- lm(MD_EARN_WNE_P10~C150_4+SATVR25+SATMT75+SATVRMID+SATMTMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.5 <- lm(MD_EARN_WNE_P10~C150_4+SATVR25+SATVRMID+SATMTMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.6 <- lm(formula = MD_EARN_WNE_P10 ~ C150_4 + SATVR25 + SATVRMID + SATMTMID + ACTENMID + ACTMTMID + AVGFACSAL, data = Uni)
Earn.7 <- lm(formula = MD_EARN_WNE_P10 ~ C150_4 + SATVRMID + SATMTMID + ACTENMID + ACTMTMID + AVGFACSAL, data = Uni)

# Re-creating linear models using glm() in order to perform LOOCV
Earn <- glm(MD_EARN_WNE_P10~SAT_AVG+C150_4+SATVR25+SATVR75+SATMT25+SATMT75+SATVRMID+SATMTMID+ACTCMMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.1 <- glm(MD_EARN_WNE_P10~SAT_AVG+C150_4+SATVR25+SATVR75+SATMT75+SATVRMID+SATMTMID+ACTCMMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.2 <- glm(MD_EARN_WNE_P10~C150_4+SATVR25+SATVR75+SATMT75+SATVRMID+SATMTMID+ACTCMMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.3 <- glm(MD_EARN_WNE_P10~C150_4+SATVR25+SATVR75+SATMT75+SATVRMID+SATMTMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.4 <- glm(MD_EARN_WNE_P10~C150_4+SATVR25+SATMT75+SATVRMID+SATMTMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.5 <- glm(MD_EARN_WNE_P10~C150_4+SATVR25+SATVRMID+SATMTMID+ACTENMID+ACTMTMID+ADM_RATE+AVGFACSAL, data = Uni)
Earn.6 <- glm(formula = MD_EARN_WNE_P10 ~ C150_4 + SATVR25 + SATVRMID + SATMTMID + ACTENMID + ACTMTMID + AVGFACSAL, data = Uni)
Earn.7 <- glm(formula = MD_EARN_WNE_P10 ~ C150_4 + SATVRMID + SATMTMID + ACTENMID + ACTMTMID + AVGFACSAL, data = Uni)

#performing LOOCV
set.seed(1)
Earn.LOOCV <- cv.glm(Uni, Earn)
Earn.1.LOOCV <- cv.glm(Uni, Earn.1)
Earn.2.LOOCV <- cv.glm(Uni, Earn.2)
Earn.3.LOOCV <- cv.glm(Uni, Earn.3)
Earn.4.LOOCV <- cv.glm(Uni, Earn.4)
Earn.5.LOOCV <- cv.glm(Uni, Earn.5)
Earn.6.LOOCV <- cv.glm(Uni, Earn.6)
Earn.7.LOOCV <- cv.glm(Uni, Earn.7)

lm.beta(Earn.6)
summ(Earn.6)
```
After selecting complete cases of all of these variables from the dataset, there were 588 observations remaining. Multiple-Linear regression was performed
using the variables described above with these observations. Various variables were removed from the model in order to try to improve the accuracy of the model
based on their significance values as long as their absence did not significantly decrease the r-Squared value of the model. Leave-one-out cross validation was
also used to compare the models to each other. The best model that was created from this method was predicting the median salary of students ten years
after they entered university based on the following independant variables: six year graduation rate(B=0.1867, p<.01), 25th percentile SAT verbal
score(B=0.1757, p=0.16), median SAT verbal score(B=-0.4093, p<0.1), median SAT math score(B=0.2424, p=0.02), median ACT english score(B=-.5058, p<.01), median
ACT math score(B=0.811, p<.01) and the average faculty salary of the universities(B=0.3330, p<.01), with F(7, 580)=176.4, p < 0.1, R^2=0.6804. As can be
observerd from the table above the SAT 25th percentile statistic was not significant(p=0.16), however removing it from the model results in a lower r-squared
value and a worse LOOCV result.. The following plot will be visualing the coefficients of the described regression model:
```{r}
plot_summs(Earn.6, scale=TRUE)
```
Observing this plot it can be seen that this model meets some intution we may have observed from the exploratoty analysis. Both six year graduation rate and
median ACT math score have large positive coefficients. What does not follow intuition from this model is that both of the reading/english based test score
variables have negative coefficients, but if we observe plots of these statistics against our dependant variable:
```{r}
ggplot(data=Uni, aes(x=SATVRMID, y=MD_EARN_WNE_P10)) + geom_jitter() + xlab("Median SAT Verbal Score") + ylab('Median Earnings Ten Years After Entering School')
```
```{r}
ggplot(data=Uni, aes(x=ACTENMID, y=MD_EARN_WNE_P10)) + geom_jitter() + xlab("Median ACT English Score") + ylab('Median Earnings Ten Years After Entering School')
```
They both seem to have a positive relationship with our dependant variable. This anomaly within the model seems to be a result of strong muticolinearity 
between the chosen dependant variables. This anomaly causes this model to be somewhat lacking in interpretability unless we want to assume that prowess in
math causes one to be financially successful while prowess in verbal communcation causes one to be lesss successful. In order to try to reduce the anomolous
affect of the multicolinearity, a dimensionality reduction was performed on all of the test statistic variables from the dataset.

(insert dimensionality reduction explanation here)
```{r}
#Pulling out data for the dimensionality reduction, all of these variables were pulled out to be used later:
New_Dat <- Uni %>% select(SATVR25, SATVR75, SATVRMID, SATMT25, SATMT75, SATMTMID, SATWR25, SATWR75, SATWRMID,
                          ACTCM25, ACTCM75, ACTCMMID, ACTEN25, ACTEN75, ACTENMID, ACTMT25, ACTMT75, ACTMTMID, ACTWR25,
                          ACTWR75, ACTWRMID, UGDS, COSTT4_A, AVGFACSAL, C150_4, PAR_ED_PCT_MS, PAR_ED_PCT_HS, PAR_ED_PCT_PS,
                          PAR_ED_PCT_1STGEN, DEP_INC_AVG, IND_INC_AVG,ADM_RATE, MD_EARN_WNE_P10)

write.csv(New_Dat, file="RawData.csv", row.names = FALSE)

#Perform the dimensionality reduction:

### --- data
dataSet <- read.csv('RawData.csv', 
                    header = T,
                    check.names = F,
                    stringsAsFactors = F)
# - keep complete observations only
dataSet <- dataSet[complete.cases(dataSet), ]

# - select test scores for
# - dimensionality reduction
dataSetPCA <- dataSet %>% select(
  starts_with('SAT'),
  starts_with('ACT')
)

### --- PCA
pcaSolution <- prcomp(dataSetPCA, scale = T, center = T)

### --- Scree Plot
# - prepare plot data.frame
pcaSolutionSummary <- as.data.frame(summary(pcaSolution)$importance)
pcaSolutionSummary <- as.data.frame(t(pcaSolutionSummary))
pcaSolutionSummary$`Proportion of Variance`
pcaSolutionSummary$Component = rownames(pcaSolutionSummary)
pcaSolutionSummary$Component <- factor(pcaSolutionSummary$Component, 
                                       levels = pcaSolutionSummary$Component, 
                                       ordered = T)
# - scree plot w. {ggplot2}
ggplot(pcaSolutionSummary, 
       aes(x = Component,
           y = `Proportion of Variance`, 
           label = round(pcaSolutionSummary$`Proportion of Variance`, 3))) + 
  geom_line(group = 1, color = "black", size = .25) + 
  geom_point(size = .75) + 
  theme_bw() + 
  geom_text_repel(size = 2) + 
  theme(axis.text.x = element_text(angle = 90))

### --- Extract the first principal component to 
### --- represent all test scores
components <- get_pca_ind(pcaSolution)
testScore <- components$coord[, 1]

### --- Create new data frame:
### --- encompass only non-test variables
### --- and use testScore to represent all
### --- test variables
dataSet2 <- dataSet %>% 
  select(
    -starts_with('SAT'),
    -starts_with('ACT')
  )
dataSet2$testScore <- testScore

### --- save the new data set:
write.csv(dataSet2, "dataSet_Reduced.csv")

```

After performing the dimensionality reduction new variables were pulled from the dataset as new independant variables for a new linear regression model, 
those new variables were:
*Number of undergraduate students enrolled
*Average cost of attendance
*Percent of students whose parents finished high school
*Percent of students whose parents had some postsecondary education
*Average family income of dependant students(as in students who are dependant on their parents)
*Average family income of dependant students(students who support themselves)
A new linear regression model was built off of these variables.
```{r}
# Importing dimensionality reduction data
reduced <- read.csv('dataSet_Reduced.csv')
reduced <- reduced %>% dplyr::select(-X, -PAR_ED_PCT_1STGEN, -PAR_ED_PCT_MS)

new_Mod <- lm(MD_EARN_WNE_P10 ~ ., data=reduced)
summ(new_Mod)
```
Above: A Summary of the model, Below: the standardized coefficiants of the model
```{r}
lm.beta(new_Mod)
```
After generating this new model, we see several interesting results which are quite puzzling from an interpretation standpoint. After all of the exploratory
analysis we performed, the new test score variable(p=0.21) was not a significant predictor in the model, while the variables that involved student
socio-economic status, such as family income and parent education were significant. Interestingly as well, the average faculty salary statistic was still
significant in this model. Visualizing the coefficients from this new model:
```{r}
plot_summs(new_Mod, scale=TRUE)
```
We observe the model somewhat contradicting itself. The model predicts a negative coefficient for both of the variables that describe parent past 
education(high school and post-secondary education). The model also predicts positive coeffients for both average income values, which is contraditory since
a higher education level generally leads to a higher incomes for families. These results are particularly disapointing as it seems that predicting future
student success with these specific statistics is not something that is necesarilly possible using the methods used in this project. 

Conclusion/Future Actions:
After observing these results from each of these models it seems that this particular dataset is not necessarily useful in determining quantitatively how
university statistics necesarily predict the success of their students later. I do believe there are future actions and studies that can be performed where
we can use these statistics to predict success. I believe that since we were able to observe many positive relationthips between test statistics and future 
earnings, if one could obtain access to these statistics that were used in these models and statistics from past students at the university, it may be more
possible to try to make quantitative generalizations about the financial successes of students using consistent information from a single university. It also
may be more interesting or meaningful to focus more on looking at financial statistics of students entering school and after they have left school to help
analyze financial decisions of students or give prospective students advice as to what path may be most financially viable to them. In general, it seemed that
tg=he best ways to maximize chances to be financially succesful was to attend a university that had a higher graduation rate. Without further investigation it
is not particularly possible to make more quantitave statements from this data without using different methods of prediction. It seems trying to attempt to
make these predictions using multiple-linear regression is very difficult, and generating an interpretable model with these independant variables is not 
necesarily effective or useful.
